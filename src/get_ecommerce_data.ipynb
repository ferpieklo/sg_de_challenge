{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORE_ENDPOINT = \"https://fakestoreapi.com/products/category/women%27s%20clothing\"\n",
    "\n",
    "r = requests.get(STORE_ENDPOINT).json()\n",
    "store_items = pd.DataFrame(r)\n",
    "\n",
    "#Explode \"rating\" (dict to columns)\n",
    "store_items = store_items.join(pd.DataFrame(store_items[\"rating\"].tolist())[[\"rate\", \"count\"]])\n",
    "store_items.drop(\"rating\", axis=1, inplace=True)\n",
    "\n",
    "store_items.rename(columns={\"price\": \"price_usd\", \"rate\": \"rating_rate\", \"count\": \"rating_count\"}, inplace=True)\n",
    "\n",
    "store_items.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(directory):\n",
    "    # get full path and basename for all files in directory\n",
    "    files = []\n",
    "    for entry in os.scandir(f'{directory}/'):\n",
    "        if entry.is_file():\n",
    "            files.append({\"path\": entry.path, \"name\": os.path.basename(entry.path)})\n",
    "        else:\n",
    "            # if the entry is a directory, recursively call get_file_paths\n",
    "            files.extend(get_file_paths(entry.path))\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ecommerce data\n",
    "dates = ['2024-02-12', '2024-02-13']\n",
    "\n",
    "data_path = '../data'\n",
    "rates_path = f'{data_path}/exchange_rates'\n",
    "\n",
    "rate_files = get_file_paths(rates_path)\n",
    "\n",
    "# I'm pulling all the rates datasets, but in a real scenario I would only pull the required dates and currencies (for example, using AWS S3 and \n",
    "# the AWS Athena query engine over parquet files)\n",
    "rates_df = pd.concat((pd.read_csv(f[\"path\"]) for f in rate_files), ignore_index=True)\n",
    "\n",
    "# Only keep USD rates for the required dates\n",
    "rates_df = rates_df[(rates_df[\"date\"].isin(dates)) & (rates_df[\"from_currency\"] == \"USD\")]\n",
    "# Drop unneeded columns\n",
    "rates_df.drop(columns=['from_currency', 'amount', 'to_currency','updated_at'], inplace=True)\n",
    "rates_df.rename(columns={'date': 'exchange_rate_date'}, inplace=True)\n",
    "\n",
    "rates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = store_items.merge(rates_df, how='cross')\n",
    "products_df[\"price_eur\"] = products_df[\"price_usd\"] * products_df[\"exchange_rate\"]\n",
    "print(products_df.columns)\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm using the DuckDB library to mimic a relational database\n",
    "# Check the \"DDL_products_big_query.sql\" file for the actual table creation script for BigQuery\n",
    "\n",
    "# Create statement for the final table\n",
    "ddl_query = \"\"\"\n",
    "        -- Drop the table if it exists\n",
    "        DROP TABLE IF EXISTS top_products;\n",
    "\n",
    "        -- Create the table with appropriate data types\n",
    "        CREATE TABLE top_products (\n",
    "            id INTEGER,\n",
    "            title STRING,\n",
    "            price_usd FLOAT,\n",
    "            description STRING,\n",
    "            category STRING,\n",
    "            image STRING,\n",
    "            rating_rate FLOAT,\n",
    "            rating_count INTEGER,\n",
    "            exchange_rate_date DATE,\n",
    "            exchange_rate FLOAT,\n",
    "            price_eur FLOAT\n",
    "        );\n",
    "    \"\"\"\n",
    "# I'm assuming that the required Top 5 products should be just five items, otherwise this would be a DENSE_RANK().\n",
    "# In a real scenario this would be improved, for example, using other fields for cases where there are multiple items with the exact same rank.\n",
    "top_products_query =\"\"\"\n",
    "        INSERT INTO\n",
    "            top_products\n",
    "        SELECT\n",
    "            id,\n",
    "            title,\n",
    "            price_usd,\n",
    "            description,\n",
    "            category,\n",
    "            image,\n",
    "            rating_rate,\n",
    "            rating_count,\n",
    "            exchange_rate_date,\n",
    "            exchange_rate,\n",
    "            price_eur\n",
    "        FROM\n",
    "            (\n",
    "                SELECT\n",
    "                    id,\n",
    "                    title,\n",
    "                    price_usd,\n",
    "                    description,\n",
    "                    category,\n",
    "                    image,\n",
    "                    rating_rate,\n",
    "                    rating_count,\n",
    "                    exchange_rate_date,\n",
    "                    exchange_rate,\n",
    "                    price_eur,\n",
    "                    rank() OVER (\n",
    "                        PARTITION BY exchange_rate_date\n",
    "                        ORDER BY\n",
    "                            rating_rate DESC\n",
    "                    ) AS rank\n",
    "                FROM\n",
    "                    all_products\n",
    "            )\n",
    "        WHERE\n",
    "            rank <= 5\n",
    "    \"\"\"\n",
    "\n",
    "# Get the data from the \"products_df\" DataFrame into DuckDB\n",
    "duckdb.sql(\"CREATE OR REPLACE TABLE all_products AS SELECT * FROM products_df\")\n",
    "# Create the \"top_products\" table\n",
    "duckdb.sql(ddl_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Insert the top products into the \"top_products\" table using the \"top_products_query\" query\n",
    "duckdb.sql(top_products_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
